import os
import pickle
import numpy as np
import mmcv
import torch
import open3d as o3d
from mmdet3d.core.bbox import LiDARInstance3DBoxes
from mmdet.datasets import PIPELINES
# å¯¼å…¥ Dataset
from data.sosdar_adapter import SOSDaRDataset 

# ==============================================================================
# é…ç½®éƒ¨åˆ†
# ==============================================================================
DATA_ROOT = '/root/autodl-tmp/FOD/data/'
INFO_PATH = os.path.join(DATA_ROOT, 'osdar23_infos_train.pkl') 
SAVE_DIR = os.path.join(DATA_ROOT, 'osdar23_gt_database')
SAVE_INFO_PATH = os.path.join(DATA_ROOT, 'osdar23_dbinfos_train.pkl') 

# ==============================================================================
# ç¨³å¥çš„ç‚¹äº‘åŠ è½½å™¨
# ==============================================================================
@PIPELINES.register_module()
class LoadPointsRobust(object):
    def __init__(self, load_dim=4, use_dim=4):
        self.load_dim = load_dim
        self.use_dim = use_dim

    def __call__(self, results):
        filename = results['pts_filename']
        points = None
        
        # 1. å°è¯•ä½œä¸º .bin è¯»å– (Numpy)
        if filename.endswith('.bin'):
            try:
                points = np.fromfile(filename, dtype=np.float32).reshape(-1, 4)
            except Exception as e:
                pass 

        # 2. å°è¯•ä½œä¸º .pcd è¯»å– (Open3D)
        elif filename.endswith('.pcd'):
            try:
                pcd = o3d.io.read_point_cloud(filename)
                points = np.asarray(pcd.points)
                if points.shape[1] == 3:
                    points = np.hstack([points, np.zeros((points.shape[0], 1))])
            except Exception as e:
                pass
        
        # 3. å¤±è´¥å¤„ç†
        if points is None:
            points = np.zeros((1, self.load_dim), dtype=np.float32)

        points = points[:, :self.use_dim]
        results['points'] = torch.from_numpy(points).float()
        return results

def create_osdar_gt_database():
    print(f"ğŸš€ [Step 2] ç”Ÿæˆ GT Database (Fix V5 - Auto Shape Adapt)...")
    
    pipeline = [
        dict(type='LoadPointsRobust', load_dim=4, use_dim=4),
        dict(type='LoadAnnotations3D', with_bbox_3d=True, with_label_3d=True),
    ]
    
    try:
        dataset = SOSDaRDataset(
            data_root=DATA_ROOT,
            ann_file=INFO_PATH,
            pipeline=pipeline,
            classes=['car', 'pedestrian', 'obstacle'],
            modality=dict(use_lidar=True, use_camera=True),
            box_type_3d='LiDAR',
            filter_empty_gt=False,
            test_mode=False
        )
    except Exception as e:
        print(f"âŒ Dataset åˆå§‹åŒ–å¤±è´¥: {e}")
        return

    mmcv.mkdir_or_exist(SAVE_DIR)
    
    all_db_infos = dict()
    for cat in dataset.CLASSES:
        all_db_infos[cat] = []

    print(f"   å‡†å¤‡å¤„ç† {len(dataset)} å¸§...")
    prog_bar = mmcv.ProgressBar(len(dataset))
    
    for i in range(len(dataset)):
        try:
            data = dataset.prepare_train_data(i)
            if data is None: 
                prog_bar.update()
                continue
            
            # 1. è§£åŒ… Points
            points = data['points']
            if isinstance(points, torch.Tensor):
                points = points.numpy()
            elif hasattr(points, 'tensor'): 
                points = points.tensor.numpy()
            
            # 2. è§£åŒ… BBoxes
            gt_bboxes_3d_obj = data['gt_bboxes_3d']
            if hasattr(gt_bboxes_3d_obj, 'tensor'):
                gt_bboxes_3d = gt_bboxes_3d_obj.tensor.numpy()
            else:
                gt_bboxes_3d = gt_bboxes_3d_obj

            # 3. è§£åŒ… Labels
            gt_labels_3d = data['gt_labels_3d']
            if isinstance(gt_labels_3d, torch.Tensor):
                gt_labels_3d = gt_labels_3d.numpy()
            
            gt_names = [dataset.CLASSES[l] for l in gt_labels_3d]
            
            # [DEBUG] æ‰“å°ç¬¬ä¸€å¸§
            if i == 0:
                print("\n" + "="*50)
                print(f"ğŸ” [DEBUG Frame 0]")
                print(f"   Points: {points.shape}")
                print(f"   Boxes:  {gt_bboxes_3d.shape}")
                print("="*50 + "\n")

            # è£å‰ªé€»è¾‘
            if gt_bboxes_3d.shape[0] > 0 and points.shape[0] > 10:
                
                # [æ ¸å¿ƒä¿®å¤ 1] åˆ‡ç‰‡ 9ç»´ -> 7ç»´
                gt_bboxes_3d_geom = gt_bboxes_3d[:, :7]
                
                # [æ ¸å¿ƒä¿®å¤ 2] æ¬è¿åˆ° GPU 
                points_cuda = torch.from_numpy(points[:, :3]).cuda().float()
                boxes_cuda = torch.from_numpy(gt_bboxes_3d_geom).cuda().float()
                
                # è®¡ç®—
                gt_boxes_lidar = LiDARInstance3DBoxes(boxes_cuda, box_dim=7)
                point_indices = gt_boxes_lidar.points_in_boxes(points_cuda)
                
                # æ¬å› CPU
                point_indices = point_indices.cpu()
                
                # [æ ¸å¿ƒä¿®å¤ 3 - V5] è‡ªåŠ¨ç»´åº¦é€‚é…
                # æœ‰çš„ç‰ˆæœ¬è¿”å› (N, M)ï¼Œæœ‰çš„è¿”å› (N,)
                is_2d_mask = (point_indices.dim() == 2)
                
                for j in range(gt_bboxes_3d.shape[0]):
                    box_name = gt_names[j]
                    
                    if is_2d_mask:
                        # 2D æ¨¡å¼: (N, M) -> å–ç¬¬ j åˆ—
                        box_point_mask = point_indices[:, j].bool().numpy()
                    else:
                        # 1D æ¨¡å¼: (N,) -> å–å€¼ç­‰äº j çš„ç‚¹
                        box_point_mask = (point_indices == j).numpy()
                    
                    box_points = points[box_point_mask]
                    
                    if box_points.shape[0] < 5: continue
                        
                    # åæ ‡å½’ä¸€åŒ–
                    box_center = gt_bboxes_3d[j][0:3]
                    box_points[:, :3] -= box_center
                    
                    info = dataset.data_infos[i]
                    filename = f"{info.get('scene_id','unk')}_{info['sample_idx']}_{box_name}_{j}.bin"
                    filepath = os.path.join(SAVE_DIR, filename)
                    box_points.tofile(filepath)
                    
                    db_info = {
                        'name': box_name,
                        'path': os.path.join('osdar23_gt_database', filename),
                        'image_idx': info['sample_idx'],
                        'gt_idx': j,
                        'box3d_lidar': gt_bboxes_3d[j],
                        'num_points_in_gt': box_points.shape[0],
                        'difficulty': 0,
                    }
                    all_db_infos[box_name].append(db_info)
                    
        except Exception as e:
            if i == 0: print(f"   âŒ å¤„ç†å‡ºé”™: {e}")
            pass
            
        prog_bar.update()

    print(f"\nğŸ’¾ ä¿å­˜æ•°æ®åº“ç´¢å¼•åˆ°: {SAVE_INFO_PATH}")
    with open(SAVE_INFO_PATH, 'wb') as f:
        pickle.dump(all_db_infos, f)
        
    for cat, infos in all_db_infos.items():
        print(f"   -> {cat}: {len(infos)} ä¸ªæ ·æœ¬")

if __name__ == '__main__':
    create_osdar_gt_database()